/// <reference path="../../../node_modules/@types/csv-parse/csv-parse.d.ts" />
"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", { value: true });
const Display = require("../../lib/force-cli-display");
const Config = require("../../lib/force-cli-config");
const Messages = require("../../lib/force-cli-messages");
const almError = require("../../lib/almError");
const logApi = require("../logApi");
const DataBulkStatus = require("./dataBulkStatusCommand");
const fs = require("fs");
const Bluebird = require("bluebird");
const readline = require("readline");
const csvsync = require("csv-parse/lib/sync");
const _ = require("lodash");
const BATCH_RECORDS_LIMIT = 10000;
const POLL_FREQUENCY_MS = 5000;
let logger;
class DataBulkUpsertCommand {
    constructor() {
        logger = logApi.child('data:bulk:upsert');
    }
    validate(context) {
    }
    execute(context) {
        return __awaiter(this, void 0, void 0, function* () {
            let csvRecords;
            let conn = yield Config.getActiveConnection(context);
            try {
                fs.statSync(context.flags.csvfile);
            }
            catch (err) {
                if (err.code === 'ENOENT') {
                    return Promise.reject(almError('PathDoesNotExist', context.flags.csvfile));
                }
                else {
                    throw err;
                }
            }
            csvRecords = fs.createReadStream(context.flags.csvfile);
            let externalId = context.flags.externalid || (yield exports.findAnExternalId(conn, context.flags.sobjecttype));
            let job = conn.bulk.createJob(context.flags.sobjecttype, 'upsert', { extIdField: externalId });
            return new Promise((resolve, reject) => __awaiter(this, void 0, void 0, function* () {
                job.on('error', function (err) {
                    reject(err);
                });
                let read = readline.createInterface(csvRecords, undefined);
                let batches;
                try {
                    batches = yield exports.splitIntoBatches(read);
                }
                catch (e) {
                    return reject(e);
                }
                resolve(yield exports.createAndExecuteBatches(conn, job, batches, context.flags.sobjectType, context.flags.wait));
            }));
        });
    }
}
exports.DataBulkUpsertCommand = DataBulkUpsertCommand;
exports.retrieveCvsStream = (context) => {
    try {
        fs.statSync(context.flags.csvfile);
    }
    catch (err) {
        if (err.code === 'ENOENT') {
            throw almError('PathDoesNotExist', context.flags.csvfile);
        }
        else {
            throw err;
        }
    }
    return fs.createReadStream(context.flags.csvfile);
};
/**
 * pick one of the possible many external ids
 * exposed for unit testing
 * @param conn {Connection}
 * @param objName {string}
 * @returns {string} - external id field name
 */
exports.findAnExternalId = function (conn, objName) {
    return __awaiter(this, void 0, void 0, function* () {
        let existingObjectMetadata = yield conn.describe(objName);
        let fields = existingObjectMetadata['fields'];
        let externalId = '';
        fields.forEach(function (field) {
            if (field['externalId']) {
                externalId = field['name'];
            }
        });
        return externalId;
    });
};
/**
 * registers the listener in charge of distributing all csv records into batches
 * exposed for unit testing
 * @param readStream - the read stream
 * @returns {Object[][]}
 */
exports.splitIntoBatches = function (readStream) {
    return __awaiter(this, void 0, void 0, function* () {
        // split all records into batches
        let batches = [];
        let batchIndex = 0;
        batches[batchIndex] = [];
        let columns = [];
        let columnsSet = false;
        let error;
        // Used to close the stream during processing so we don't keep reading.
        const closeStream = () => {
            if (_.isFunction(readStream.close)) {
                readStream.close();
            }
            // Don't rely on the close event, force the promise to reject now.
            return readStream.emit('close', error);
        };
        readStream.on('line', function (line) {
            // Ending the stream still may still process some
            // of the data, so ignore it if we already captured
            // an error
            //
            // Also ignore empty lines
            if (error || _.isEmpty(line.trim())) {
                return;
            }
            if (!columnsSet) {
                try {
                    columns = csvsync(line)[0];
                    columnsSet = true;
                    return;
                }
                catch (err) {
                    error = err;
                    return closeStream();
                }
            }
            if (batches[batchIndex].length === BATCH_RECORDS_LIMIT) {
                // next batch
                batchIndex++;
                batches[batchIndex] = [];
            }
            let record = {};
            let values;
            try {
                values = csvsync(line)[0];
            }
            catch (err) {
                error = err;
                return closeStream();
            }
            // checked manually instead of using csv-parse's options because the errors from improper csv
            // would prevent the display of mocha's results. Invalid records will be detected by the server anyways
            if (values.length !== columns.length) {
                error = new Error(Messages.get('DataBulkUpsertCsvWrongNumberFields', ((batchIndex * BATCH_RECORDS_LIMIT) + batches[batchIndex].length + 1), values.length, columns.length));
                return closeStream();
            }
            let index = 0;
            columns.forEach(function (column) {
                record[column] = values[index];
                index++;
            });
            batches[batchIndex].push(record);
        });
        return new Promise((resolve, reject) => {
            readStream.on('close', (err) => {
                if (error || err) {
                    reject(error || err);
                }
                else {
                    resolve(batches);
                }
            });
            readStream.on('end', err => reject(error || err));
        });
    });
};
/**
 * create and execute batches based on the record arrays; wait for completion response if -w flag is set with > 0 minutes
 * exposed for unit testing
 * @param conn {Connection}
 * @param job {Job}
 * @param batches {Object[][]}
 * @param sobjectType {string}
 * @param wait {number}
 */
exports.createAndExecuteBatches = function (conn, job, batches, sobjectType, wait) {
    return __awaiter(this, void 0, void 0, function* () {
        let batchesCompleted = 0;
        let overallInfo = false;
        // The error handling for this gets quite tricky when there are multiple batches
        // Currently, we bail out early by calling an Error.exit
        // But, we might want to actually continue to the next batch.
        return yield Bluebird.all(batches.map(function (batch, i) {
            return __awaiter(this, void 0, void 0, function* () {
                const newBatch = job.createBatch();
                return new Promise((resolve, reject) => {
                    newBatch.on('error', function (err) {
                        // reword no external id error message to direct it to org user rather than api user
                        if (err.message.startsWith('External ID was blank')) {
                            err.message = Messages.get('DataBulkUpsertExternalIdRequired', sobjectType);
                        }
                        if (err.message.startsWith('Polling time out')) {
                            let jobIdIndex = err.message.indexOf('750');
                            let batchIdIndex = err.message.indexOf('751');
                            Display.info(Messages.get('DataBulkTimeOut', err.message.substr(jobIdIndex, 18), err.message.substr(batchIdIndex, 18)));
                        }
                        reject(err.message);
                    });
                    if (!wait) {
                        newBatch.on('queue', function (batchInfo) {
                            return __awaiter(this, void 0, void 0, function* () {
                                Display.info(Messages.get('DataBulkUpsertCheckStatusCommand', (i + 1), batchInfo.jobId, batchInfo.id));
                                resolve(batchInfo);
                            });
                        });
                    }
                    else {
                        if (wait <= 0) {
                            reject(Messages.get('WaitTimeError'));
                        }
                        resolve(exports.waitForCompletion(conn, newBatch, batchesCompleted, overallInfo, i + 1, batches.length, wait));
                    }
                    newBatch.execute(batch, (err, result) => {
                        if (err) {
                            reject(err);
                        }
                    });
                });
            });
        }));
    });
};
/**
 * register completion event listeners on the batch
 * exposed for unit testing
 * @param conn
 * @param newBatch
 * @param batchesCompleted
 * @param overallInfo
 * @param batchNum
 * @param totalNumBatches
 */
exports.waitForCompletion = function (conn, newBatch, batchesCompleted, overallInfo, batchNum, totalNumBatches, waitMins) {
    return __awaiter(this, void 0, void 0, function* () {
        return new Promise((resolve, reject) => {
            newBatch.on('queue', function (batchInfo) {
                if (!overallInfo) {
                    Display.info(Messages.get('DataBulkUpsertPollingInfo', POLL_FREQUENCY_MS / 1000, batchInfo.jobId));
                    overallInfo = true;
                }
                Display.info(Messages.get('DataBulkUpsertBatchQueued', batchNum, batchInfo.id));
                newBatch.poll(POLL_FREQUENCY_MS, waitMins * 60000);
            });
            newBatch.on('response', function (results) {
                return __awaiter(this, void 0, void 0, function* () {
                    let summary = yield newBatch.check();
                    Display.bulkBatchStatus(summary, results, batchNum);
                    batchesCompleted++;
                    if (batchesCompleted === totalNumBatches) {
                        resolve(yield DataBulkStatus.fetchAndDisplayJobStatus(conn, summary.jobId));
                    }
                });
            });
        });
    });
};

//# sourceMappingURL=dataBulkUpsertCommand.js.map
